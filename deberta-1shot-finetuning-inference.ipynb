{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-26T17:41:12.257896Z","iopub.execute_input":"2022-06-26T17:41:12.258504Z","iopub.status.idle":"2022-06-26T17:41:12.264313Z","shell.execute_reply.started":"2022-06-26T17:41:12.258467Z","shell.execute_reply":"2022-06-26T17:41:12.263083Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import log_loss\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig, get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:41:12.563874Z","iopub.execute_input":"2022-06-26T17:41:12.564232Z","iopub.status.idle":"2022-06-26T17:41:12.570560Z","shell.execute_reply.started":"2022-06-26T17:41:12.564203Z","shell.execute_reply":"2022-06-26T17:41:12.569513Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/feedback-prize-effectiveness/train.csv')\ntest_data = pd.read_csv('/kaggle/input/feedback-prize-effectiveness/test.csv')\n\ntrain_data['text'] = train_data['essay_id'].apply(lambda x: open(f'/kaggle/input/feedback-prize-effectiveness/train/{x}.txt').read())\ntest_data['text'] = test_data['essay_id'].apply(lambda x: open(f'/kaggle/input/feedback-prize-effectiveness/test/{x}.txt').read())\ntrain_data.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:41:13.450423Z","iopub.execute_input":"2022-06-26T17:41:13.451060Z","iopub.status.idle":"2022-06-26T17:41:38.040396Z","shell.execute_reply.started":"2022-06-26T17:41:13.451028Z","shell.execute_reply":"2022-06-26T17:41:38.039503Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\ntrain_data['discourse_effectiveness'] = encoder.fit_transform(train_data['discourse_effectiveness'])\ntrain_data['discourse_type'] = encoder.fit_transform(train_data['discourse_type'])\ntest_data['discourse_type'] = encoder.fit_transform(test_data['discourse_type'])","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:41:38.042188Z","iopub.execute_input":"2022-06-26T17:41:38.042559Z","iopub.status.idle":"2022-06-26T17:41:38.074099Z","shell.execute_reply.started":"2022-06-26T17:41:38.042523Z","shell.execute_reply":"2022-06-26T17:41:38.073052Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class EssayDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len=512):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.discourse_type = df['discourse_type'].values\n        self.discourse = df['discourse_text'].values\n        self.essay = df['text'].values\n        if 'discourse_effectiveness' in self.df:\n            self.target = df['discourse_effectiveness'].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        discourse_type = self.discourse_type[idx]\n        discourse = self.discourse[idx]\n        essay = self.essay[idx]\n        text = discourse + \" \" + self.tokenizer.sep_token + \" \" + essay\n\n        encode_dict = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            truncation=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n        ids = encode_dict['input_ids']\n        mask = encode_dict['attention_mask']\n\n        ids = ids.squeeze(0)\n        mask = mask.squeeze(0)\n\n        if 'discourse_effectiveness' in self.df:\n            target = self.target[idx]\n            return {\"ids\" : ids, \"mask\": mask, \"target\": target, \"dense_feature\": discourse_type}\n        return {\"ids\": ids, \"mask\": mask, \"dense_feature\": discourse_type}","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:41:38.075662Z","iopub.execute_input":"2022-06-26T17:41:38.076030Z","iopub.status.idle":"2022-06-26T17:41:38.088444Z","shell.execute_reply.started":"2022-06-26T17:41:38.075994Z","shell.execute_reply":"2022-06-26T17:41:38.087142Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model_name = 'microsoft/deberta-v3-base'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:41:38.091256Z","iopub.execute_input":"2022-06-26T17:41:38.092159Z","iopub.status.idle":"2022-06-26T17:41:42.918517Z","shell.execute_reply.started":"2022-06-26T17:41:38.092121Z","shell.execute_reply":"2022-06-26T17:41:42.917572Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"max_len = 512\ntrain_data_, valid_data_ = train_test_split(train_data, test_size=0.2, random_state=42)\ntrain_dataset = EssayDataset(train_data_, tokenizer, max_len)\nvalid_dataset = EssayDataset(valid_data_, tokenizer, max_len)\ntest_dataset = EssayDataset(test_data, tokenizer, max_len)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:41:42.922447Z","iopub.execute_input":"2022-06-26T17:41:42.924946Z","iopub.status.idle":"2022-06-26T17:41:42.950884Z","shell.execute_reply.started":"2022-06-26T17:41:42.924910Z","shell.execute_reply":"2022-06-26T17:41:42.948788Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class FeedBackModel(nn.Module):\n    def __init__(self, model_name):\n        super(FeedBackModel, self).__init__()\n        self.deberta = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=10, output_attentions=False, output_hidden_states=False)\n        self.dropout = nn.Dropout(0.2)\n        self.fc = nn.Linear(10+1, 3)\n        \n    def forward(self, batch):        \n        input_ids, attention_masks, dense_feature = batch['ids'], batch['mask'], batch['dense_feature']\n        out = self.deberta(input_ids, attention_mask=attention_masks, output_hidden_states=False)\n        output = self.dropout(out.logits)\n        dense_feature = dense_feature.reshape((-1, 1))\n        output = torch.concat([out.logits, dense_feature], dim=-1)\n        output = self.fc(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:41:42.952316Z","iopub.execute_input":"2022-06-26T17:41:42.952913Z","iopub.status.idle":"2022-06-26T17:41:42.969388Z","shell.execute_reply.started":"2022-06-26T17:41:42.952865Z","shell.execute_reply":"2022-06-26T17:41:42.968398Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class Classifier(pl.LightningModule):\n    def __init__(self, hparams, model):\n        super(Classifier, self).__init__()\n        self.save_hyperparameters(ignore=['model'])\n\n        self.model = model\n        self.batch_size = hparams[\"batch_size\"]\n        self.lr = hparams[\"lr\"]\n        self.wd = hparams['weight_decay']\n        self.steps = hparams['total_steps']\n\n\n    def forward(self, batch):\n        output = self.model(batch)\n        return output\n\n    def configure_optimizers(self):\n        optimizer = optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=self.wd)\n        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=int(self.steps * 0.1), num_training_steps=self.steps)\n        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n        return [optimizer], [scheduler]\n\n    def training_step(self, batch, batch_idx):\n        output = self.forward(batch)\n        pred_flat = torch.argmax(output, dim=1).flatten()\n        labels_flat = batch['target'].flatten()\n        loss = F.cross_entropy(output, labels_flat)\n        acc = torch.sum(pred_flat == labels_flat) / len(labels_flat)\n        self.log(\"train_loss\", loss, on_epoch=True, on_step=False)\n        self.log(\"train_acc\", acc, on_epoch=True, on_step=False)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        output = self.forward(batch)\n        pred_flat = torch.argmax(output, dim=1).flatten()\n        labels_flat = batch['target'].flatten()\n        loss = F.cross_entropy(output, labels_flat)\n        acc = torch.sum(pred_flat == labels_flat) / len(labels_flat)\n        self.log(\"val_loss\", loss)\n        self.log(\"val_acc\", acc)\n\n    def train_dataloader(self):\n        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n        return train_loader\n\n    def val_dataloader(self):\n        valid_loader = DataLoader(valid_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n        return valid_loader\n\n    def test_dataloader(self):\n        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n        return test_loader","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:41:42.970732Z","iopub.execute_input":"2022-06-26T17:41:42.975649Z","iopub.status.idle":"2022-06-26T17:41:42.998844Z","shell.execute_reply.started":"2022-06-26T17:41:42.975604Z","shell.execute_reply":"2022-06-26T17:41:42.997814Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"pl.seed_everything(42)\nhparams = {\n    \"batch_size\": 16,\n    \"lr\": 2e-5,\n    \"weight_decay\": 1e-2,\n    \"epochs\": 1,\n}\nloader = DataLoader(train_dataset, batch_size=hparams[\"batch_size\"])\nhparams[\"total_steps\"] = len(loader) * hparams[\"epochs\"]","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:41:43.000010Z","iopub.execute_input":"2022-06-26T17:41:43.000554Z","iopub.status.idle":"2022-06-26T17:41:43.019995Z","shell.execute_reply.started":"2022-06-26T17:41:43.000520Z","shell.execute_reply":"2022-06-26T17:41:43.018799Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"feedback_model = FeedBackModel(model_name)\nlightning = Classifier(hparams, feedback_model)\n\ncheckpoint_callback = ModelCheckpoint(\n    monitor=\"val_loss\",\n    dirpath=\"./ckpts/\",\n    mode='min',\n    filename='best',\n)\n\ntrainer = pl.Trainer(\n    gpus=1, \n    max_epochs=hparams[\"epochs\"], \n    precision=16, \n    gradient_clip_val=1.0, \n    val_check_interval=0.5,\n    callbacks=[checkpoint_callback]\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:41:43.021818Z","iopub.execute_input":"2022-06-26T17:41:43.022443Z","iopub.status.idle":"2022-06-26T17:41:54.525361Z","shell.execute_reply.started":"2022-06-26T17:41:43.022408Z","shell.execute_reply":"2022-06-26T17:41:54.524434Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"trainer.fit(lightning)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:43:06.281278Z","iopub.execute_input":"2022-06-26T17:43:06.282364Z","iopub.status.idle":"2022-06-26T18:30:15.742055Z","shell.execute_reply.started":"2022-06-26T17:43:06.282279Z","shell.execute_reply":"2022-06-26T18:30:15.737863Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"predictions = trainer.predict(dataloaders=lightning.test_dataloader(), ckpt_path='best')","metadata":{"execution":{"iopub.status.busy":"2022-06-26T18:30:18.689906Z","iopub.execute_input":"2022-06-26T18:30:18.690677Z","iopub.status.idle":"2022-06-26T18:30:23.311409Z","shell.execute_reply.started":"2022-06-26T18:30:18.690634Z","shell.execute_reply":"2022-06-26T18:30:23.310270Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"preds = []\nfor batch in predictions:\n    preds.append(batch)\n\npreds = torch.concat(preds)\npreds = preds.type(torch.float32)\npreds = F.softmax(preds, dim=1)\n\nsample = pd.read_csv(\"/kaggle/input/feedback-prize-effectiveness/sample_submission.csv\")\nsample['Adequate'] = preds[:, 0]\nsample['Effective'] = preds[:, 1]\nsample['Ineffective'] = preds[:, 2]\nprint(sample.head())\nsample.to_csv(\"deberta_submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T18:31:32.944207Z","iopub.execute_input":"2022-06-26T18:31:32.944876Z","iopub.status.idle":"2022-06-26T18:31:32.974971Z","shell.execute_reply.started":"2022-06-26T18:31:32.944836Z","shell.execute_reply":"2022-06-26T18:31:32.973970Z"},"trusted":true},"execution_count":17,"outputs":[]}]}