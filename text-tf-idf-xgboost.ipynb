{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\ntqdm.pandas()\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import OneHotEncoder,LabelEncoder\nfrom scipy import sparse\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import log_loss\n# import re\n# import nltk\n# from nltk.corpus import stopwords\n# from nltk.stem.porter import PorterStemmer\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-28T03:55:12.288474Z","iopub.execute_input":"2022-06-28T03:55:12.28892Z","iopub.status.idle":"2022-06-28T03:55:12.299143Z","shell.execute_reply.started":"2022-06-28T03:55:12.288883Z","shell.execute_reply":"2022-06-28T03:55:12.297905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/feedback-prize-effectiveness/train.csv')\ntest_data = pd.read_csv('/kaggle/input/feedback-prize-effectiveness/test.csv')\n\ntrain_data['text'] = train_data['essay_id'].apply(lambda x: open(f'/kaggle/input/feedback-prize-effectiveness/train/{x}.txt').read())\ntest_data['text'] = test_data['essay_id'].apply(lambda x: open(f'/kaggle/input/feedback-prize-effectiveness/test/{x}.txt').read())\ntrain_data.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T03:55:12.315512Z","iopub.execute_input":"2022-06-28T03:55:12.316666Z","iopub.status.idle":"2022-06-28T03:55:31.855569Z","shell.execute_reply.started":"2022-06-28T03:55:12.316603Z","shell.execute_reply":"2022-06-28T03:55:31.854368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\ntrain_data['discourse_effectiveness'] = encoder.fit_transform(train_data['discourse_effectiveness'])\ntrain_data['discourse_type'] = encoder.fit_transform(train_data['discourse_type'])\ntest_data['discourse_type'] = encoder.fit_transform(test_data['discourse_type'])","metadata":{"execution":{"iopub.status.busy":"2022-06-28T03:55:31.857799Z","iopub.execute_input":"2022-06-28T03:55:31.858853Z","iopub.status.idle":"2022-06-28T03:55:31.893158Z","shell.execute_reply.started":"2022-06-28T03:55:31.858809Z","shell.execute_reply":"2022-06-28T03:55:31.891635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\nfor i,(train_index, test_index) in enumerate(skfold.split(train_data, train_data[\"discourse_effectiveness\"])):\n    train_data.loc[test_index,\"fold\"] = i","metadata":{"execution":{"iopub.status.busy":"2022-06-28T03:55:31.895889Z","iopub.execute_input":"2022-06-28T03:55:31.896704Z","iopub.status.idle":"2022-06-28T03:55:31.919928Z","shell.execute_reply.started":"2022-06-28T03:55:31.89665Z","shell.execute_reply":"2022-06-28T03:55:31.918946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf_idf = TfidfVectorizer(ngram_range=(1,2),norm='l2', smooth_idf=True)\none_hot_encode = OneHotEncoder()\npreds = []","metadata":{"execution":{"iopub.status.busy":"2022-06-28T03:58:56.355262Z","iopub.execute_input":"2022-06-28T03:58:56.356305Z","iopub.status.idle":"2022-06-28T03:58:56.361887Z","shell.execute_reply.started":"2022-06-28T03:58:56.356263Z","shell.execute_reply":"2022-06-28T03:58:56.360703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(5):\n    train_data_ = train_data[train_data['fold']!=fold]\n    eval_data_ = train_data[train_data['fold']==fold]\n    \n    train_discourse_tfidf = tf_idf.fit_transform(train_data_[\"discourse_text\"])\n    eval_discourse_tfidf = tf_idf.transform(eval_data_[\"discourse_text\"])\n    test_discourse_tfidf = tf_idf.transform(test_data[\"discourse_text\"])\n    \n    train_text_tfidf = tf_idf.fit_transform(train_data_[\"text\"])\n    eval_text_tfidf = tf_idf.transform(eval_data_[\"text\"])\n    test_text_tfidf = tf_idf.transform(test_data[\"text\"])\n    \n    one_hot_encoded_train_data =  sparse.csr_matrix(one_hot_encode.fit_transform(train_data_[\"discourse_type\"].values.reshape(-1,1)))\n    one_hot_encoded_eval_data =  sparse.csr_matrix(one_hot_encode.transform(eval_data_[\"discourse_type\"].values.reshape(-1,1)))\n    one_hot_encoded_test_data =  sparse.csr_matrix(one_hot_encode.transform(test_data[\"discourse_type\"].values.reshape(-1,1)))\n    \n    train_tfidf = sparse.hstack((one_hot_encoded_train_data,train_discourse_tfidf,train_text_tfidf))\n    eval_tfidf = sparse.hstack((one_hot_encoded_eval_data,eval_discourse_tfidf,eval_text_tfidf))\n    test_tfidf = sparse.hstack((one_hot_encoded_test_data,test_discourse_tfidf,test_text_tfidf))\n    \n    clf = XGBClassifier(random_state=42, seed=2, colsample_bytree=0.6, subsample=0.7)\n    clf.fit(train_tfidf, train_data_[\"discourse_effectiveness\"].values)\n    \n    eval_preds = clf.predict_proba(eval_tfidf)\n    eval_loss = log_loss(eval_data_[\"discourse_effectiveness\"].values,eval_preds)\n    print(\"Fold : {} EV score: {}\".format(fold,eval_loss))\n    \n    preds.append(clf.predict_proba(test_tfidf))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T03:58:56.561353Z","iopub.execute_input":"2022-06-28T03:58:56.562451Z","iopub.status.idle":"2022-06-28T04:01:54.953726Z","shell.execute_reply.started":"2022-06-28T03:58:56.562395Z","shell.execute_reply":"2022-06-28T04:01:54.951031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_data = pd.read_csv(\"../input/feedback-prize-effectiveness/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-28T04:01:54.955561Z","iopub.status.idle":"2022-06-28T04:01:54.957159Z","shell.execute_reply.started":"2022-06-28T04:01:54.956776Z","shell.execute_reply":"2022-06-28T04:01:54.956825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_result = np.array(preds).mean(0)\nsubmission_data.loc[:,\"Ineffective\"] = final_result[:,0]\nsubmission_data.loc[:,\"Adequate\"] = final_result[:,1]\nsubmission_data.loc[:,\"Effective\"] = final_result[:,2]\nsubmission_data.to_csv('submission.csv',index=None)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T04:01:54.960413Z","iopub.status.idle":"2022-06-28T04:01:54.963204Z","shell.execute_reply.started":"2022-06-28T04:01:54.962813Z","shell.execute_reply":"2022-06-28T04:01:54.962854Z"},"trusted":true},"execution_count":null,"outputs":[]}]}