{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-30T05:20:12.131843Z","iopub.execute_input":"2022-06-30T05:20:12.132228Z","iopub.status.idle":"2022-06-30T05:20:12.137729Z","shell.execute_reply.started":"2022-06-30T05:20:12.132196Z","shell.execute_reply":"2022-06-30T05:20:12.136765Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import log_loss\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig, get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2022-06-30T05:20:12.507539Z","iopub.execute_input":"2022-06-30T05:20:12.507899Z","iopub.status.idle":"2022-06-30T05:20:21.113232Z","shell.execute_reply.started":"2022-06-30T05:20:12.507871Z","shell.execute_reply":"2022-06-30T05:20:21.112104Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/feedback-prize-effectiveness/train.csv')\ntest_data = pd.read_csv('/kaggle/input/feedback-prize-effectiveness/test.csv')\n\ntrain_data['text'] = train_data['essay_id'].apply(lambda x: open(f'/kaggle/input/feedback-prize-effectiveness/train/{x}.txt').read())\ntest_data['text'] = test_data['essay_id'].apply(lambda x: open(f'/kaggle/input/feedback-prize-effectiveness/test/{x}.txt').read())\ntrain_data.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T05:20:21.115686Z","iopub.execute_input":"2022-06-30T05:20:21.116509Z","iopub.status.idle":"2022-06-30T05:20:46.539187Z","shell.execute_reply.started":"2022-06-30T05:20:21.116456Z","shell.execute_reply":"2022-06-30T05:20:46.538282Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   discourse_id      essay_id  \\\n0  0013cc385424  007ACE74B050   \n1  9704a709b505  007ACE74B050   \n\n                                      discourse_text discourse_type  \\\n0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n1  On my perspective, I think that the face is a ...       Position   \n\n  discourse_effectiveness                                               text  \n0                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n1                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>discourse_id</th>\n      <th>essay_id</th>\n      <th>discourse_text</th>\n      <th>discourse_type</th>\n      <th>discourse_effectiveness</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0013cc385424</td>\n      <td>007ACE74B050</td>\n      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n      <td>Lead</td>\n      <td>Adequate</td>\n      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9704a709b505</td>\n      <td>007ACE74B050</td>\n      <td>On my perspective, I think that the face is a ...</td>\n      <td>Position</td>\n      <td>Adequate</td>\n      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"encoder = LabelEncoder()\ntrain_data['discourse_effectiveness'] = encoder.fit_transform(train_data['discourse_effectiveness'])\ntrain_data['discourse_type'] = encoder.fit_transform(train_data['discourse_type'])\ntest_data['discourse_type'] = encoder.fit_transform(test_data['discourse_type'])","metadata":{"execution":{"iopub.status.busy":"2022-06-30T05:20:46.540636Z","iopub.execute_input":"2022-06-30T05:20:46.540992Z","iopub.status.idle":"2022-06-30T05:20:46.573125Z","shell.execute_reply.started":"2022-06-30T05:20:46.540957Z","shell.execute_reply":"2022-06-30T05:20:46.572258Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class EssayDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.discourse_type = df['discourse_type'].values\n        self.discourse = df['discourse_text'].values\n        self.essay = df['text'].values\n        if 'discourse_effectiveness' in self.df:\n            self.target = df['discourse_effectiveness'].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        discourse_type = self.discourse_type[idx]\n        discourse = self.discourse[idx]\n        essay = self.essay[idx]\n        text = discourse + \" \" + self.tokenizer.sep_token + \" \" + essay\n\n        encode_dict = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            truncation=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n        ids = encode_dict['input_ids']\n        mask = encode_dict['attention_mask']\n\n        ids = ids.squeeze(0)\n        mask = mask.squeeze(0)\n\n        if 'discourse_effectiveness' in self.df:\n            target = self.target[idx]\n            return {\"ids\" : ids, \"mask\": mask, \"target\": target, \"dense_feature\": discourse_type}\n        return {\"ids\": ids, \"mask\": mask, \"dense_feature\": discourse_type}","metadata":{"execution":{"iopub.status.busy":"2022-06-30T05:20:46.576084Z","iopub.execute_input":"2022-06-30T05:20:46.576472Z","iopub.status.idle":"2022-06-30T05:20:46.586748Z","shell.execute_reply.started":"2022-06-30T05:20:46.576424Z","shell.execute_reply":"2022-06-30T05:20:46.585606Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# model_name = 'microsoft/deberta-v3-base'\nmodel_name = '../input/deberta-v3-base/deberta-v3-base'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.save_pretrained('.')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T05:20:46.588369Z","iopub.execute_input":"2022-06-30T05:20:46.588751Z","iopub.status.idle":"2022-06-30T05:20:51.314657Z","shell.execute_reply.started":"2022-06-30T05:20:46.588715Z","shell.execute_reply":"2022-06-30T05:20:51.313663Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab9acd49ffb44feb9e89a50ad4435db0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8599e51d4ce844fc8c6de5950632c70e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1af41d4c98b64db9965f951be8049b1b"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"max_len = 256\ntrain_data_, valid_data_ = train_test_split(train_data, test_size=0.2, random_state=42)\ntrain_dataset = EssayDataset(train_data_, tokenizer, max_len)\nvalid_dataset = EssayDataset(valid_data_, tokenizer, max_len)\ntest_dataset = EssayDataset(test_data, tokenizer, max_len)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T05:20:51.316226Z","iopub.execute_input":"2022-06-30T05:20:51.316852Z","iopub.status.idle":"2022-06-30T05:20:51.336379Z","shell.execute_reply.started":"2022-06-30T05:20:51.316794Z","shell.execute_reply":"2022-06-30T05:20:51.335486Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class FeedBackModel(nn.Module):\n    def __init__(self, model_name):\n        super(FeedBackModel, self).__init__()\n        self.deberta = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3, output_attentions=False, output_hidden_states=False)\n        self.dropout = nn.Dropout(0.2)\n        self.fc = nn.Linear(3+1, 3)#10\n        \n    def forward(self, batch):        \n        input_ids, attention_masks, dense_feature = batch['ids'], batch['mask'], batch['dense_feature']\n        out = self.deberta(input_ids, attention_mask=attention_masks, output_hidden_states=False)\n        output = self.dropout(out.logits)\n        dense_feature = dense_feature.reshape((-1, 1))\n        output = torch.concat([out.logits, dense_feature], dim=-1)\n        output = self.fc(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-06-30T05:20:51.337956Z","iopub.execute_input":"2022-06-30T05:20:51.338607Z","iopub.status.idle":"2022-06-30T05:20:51.349642Z","shell.execute_reply.started":"2022-06-30T05:20:51.338569Z","shell.execute_reply":"2022-06-30T05:20:51.348538Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class Classifier(pl.LightningModule):\n    def __init__(self, hparams, model):\n        super(Classifier, self).__init__()\n        self.save_hyperparameters(ignore=['model'])\n\n        self.model = model\n        self.batch_size = hparams[\"batch_size\"]\n        self.lr = hparams[\"lr\"]\n        self.wd = hparams['weight_decay']\n        self.steps = hparams['total_steps']\n\n\n    def forward(self, batch):\n        output = self.model(batch)\n        return output\n\n    def configure_optimizers(self):\n        optimizer = optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=self.wd)\n        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=int(self.steps * 0.1), num_training_steps=self.steps)\n        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n        return [optimizer], [scheduler]\n\n    def training_step(self, batch, batch_idx):\n        output = self.forward(batch)\n        pred_flat = torch.argmax(output, dim=1).flatten()\n        labels_flat = batch['target'].flatten()\n        loss = F.cross_entropy(output, labels_flat)\n        acc = torch.sum(pred_flat == labels_flat) / len(labels_flat)\n        self.log(\"train_loss\", loss, on_epoch=True, on_step=False)\n        self.log(\"train_acc\", acc, on_epoch=True, on_step=False)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        output = self.forward(batch)\n        pred_flat = torch.argmax(output, dim=1).flatten()\n        labels_flat = batch['target'].flatten()\n        loss = F.cross_entropy(output, labels_flat)\n        acc = torch.sum(pred_flat == labels_flat) / len(labels_flat)\n        self.log(\"val_loss\", loss)\n        self.log(\"val_acc\", acc)\n\n    def train_dataloader(self):\n        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n        return train_loader\n\n    def val_dataloader(self):\n        valid_loader = DataLoader(valid_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n        return valid_loader\n\n    def test_dataloader(self):\n        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n        return test_loader","metadata":{"execution":{"iopub.status.busy":"2022-06-30T05:20:51.351327Z","iopub.execute_input":"2022-06-30T05:20:51.352027Z","iopub.status.idle":"2022-06-30T05:20:51.369490Z","shell.execute_reply.started":"2022-06-30T05:20:51.351987Z","shell.execute_reply":"2022-06-30T05:20:51.368569Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"pl.seed_everything(42)\nhparams = {\n    \"batch_size\": 16,\n    \"lr\": 2e-5,\n    \"weight_decay\": 1e-2,\n    \"epochs\": 1,\n}\nloader = DataLoader(train_dataset, batch_size=hparams[\"batch_size\"])\nhparams[\"total_steps\"] = len(loader) * hparams[\"epochs\"]","metadata":{"execution":{"iopub.status.busy":"2022-06-30T05:20:51.370673Z","iopub.execute_input":"2022-06-30T05:20:51.371013Z","iopub.status.idle":"2022-06-30T05:20:51.388274Z","shell.execute_reply.started":"2022-06-30T05:20:51.370980Z","shell.execute_reply":"2022-06-30T05:20:51.387093Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"feedback_model = FeedBackModel(model_name)\nlightning = Classifier(hparams, feedback_model)\n\n# checkpoint_callback = ModelCheckpoint(\n#     monitor=\"val_loss\",\n#     dirpath=\"./ckpts/\",\n#     mode='min',\n#     filename='best',\n# )\n\ntrainer = pl.Trainer(\n    gpus=1, \n    max_epochs=hparams[\"epochs\"], \n    precision=16, \n    gradient_clip_val=1.0, \n    val_check_interval=0.5,)\n#     callbacks=[checkpoint_callback]\n# )","metadata":{"execution":{"iopub.status.busy":"2022-06-30T06:46:58.864422Z","iopub.execute_input":"2022-06-30T06:46:58.864859Z","iopub.status.idle":"2022-06-30T06:46:58.957849Z","shell.execute_reply.started":"2022-06-30T06:46:58.864772Z","shell.execute_reply":"2022-06-30T06:46:58.956388Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/1123768173.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeedback_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeedBackModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlightning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeedback_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# checkpoint_callback = ModelCheckpoint(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     monitor=\"val_loss\",\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'FeedBackModel' is not defined"],"ename":"NameError","evalue":"name 'FeedBackModel' is not defined","output_type":"error"}]},{"cell_type":"code","source":"trainer.fit(lightning)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T05:26:26.741893Z","iopub.execute_input":"2022-06-30T05:26:26.742249Z","iopub.status.idle":"2022-06-30T05:47:07.680220Z","shell.execute_reply.started":"2022-06-30T05:26:26.742219Z","shell.execute_reply":"2022-06-30T05:47:07.679044Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc38676de7364e76bfb616b2255bd75a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"predictions = trainer.predict(dataloaders=lightning.test_dataloader(), ckpt_path='best')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T05:50:05.810535Z","iopub.execute_input":"2022-06-30T05:50:05.810938Z","iopub.status.idle":"2022-06-30T05:50:10.709947Z","shell.execute_reply.started":"2022-06-30T05:50:05.810904Z","shell.execute_reply":"2022-06-30T05:50:10.708863Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Predicting: 1839it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4070693d56fa4c8f90ec6380255f4a6c"}},"metadata":{}}]},{"cell_type":"code","source":"preds = []\nfor batch in predictions:\n    preds.append(batch)\n\npreds = torch.concat(preds)\npreds = preds.type(torch.float32)\npreds = F.softmax(preds, dim=1)\n\nsample = pd.read_csv(\"../input/feedback-prize-effectiveness/sample_submission.csv\")\nsample['Adequate'] = preds[:, 0]\nsample['Effective'] = preds[:, 1]\nsample['Ineffective'] = preds[:, 2]\nprint(sample.head())\nsample.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T06:03:49.782121Z","iopub.execute_input":"2022-06-30T06:03:49.782473Z","iopub.status.idle":"2022-06-30T06:03:49.800637Z","shell.execute_reply.started":"2022-06-30T06:03:49.782444Z","shell.execute_reply":"2022-06-30T06:03:49.799371Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"   discourse_id  Ineffective  Adequate  Effective\n0  a261b6e14276     0.023983  0.149372   0.826645\n1  5a88900e7dc1     0.015400  0.069017   0.915583\n2  9790d835736b     0.036903  0.404964   0.558133\n3  75ce6d68b67b     0.036782  0.398155   0.565064\n4  93578d946723     0.037340  0.424833   0.537827\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}